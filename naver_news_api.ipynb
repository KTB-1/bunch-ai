{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 뉴스 API 연결해서 뉴스 스크래핑\n",
    "[참고 자료]\n",
    "* https://developers.naver.com/docs/serviceapi/search/blog/blog.md#%EA%B2%80%EC%83%89-api-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EA%B2%80%EC%83%89-%EA%B5%AC%ED%98%84-%EC%98%88%EC%A0%9C\n",
    "* https://contents.premium.naver.com/chatgpt/buff/contents/231204223117640hg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_CLIENT_ID = \"hZm0ny7bv69wAHcdYffq\"\n",
    "MY_CLIENT_SECRET = \"pIyAPPtzD2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 'news_data.csv'로 저장되었습니다.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Title</th>\n",
       "      <th>Original Link</th>\n",
       "      <th>Publication Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>주식</td>\n",
       "      <td>'부동산보단 주식'…투자 전환 강조한 김병환 금융위원장</td>\n",
       "      <td>https://www.hankyung.com/article/2024081288721</td>\n",
       "      <td>Mon, 12 Aug 2024 17:51:00 +0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>주식</td>\n",
       "      <td>국민연금 \"핀란드 주식투자 배당 세금 96억원 환급 소송 승소\"</td>\n",
       "      <td>https://www.yna.co.kr/view/AKR2024081205530053...</td>\n",
       "      <td>Mon, 12 Aug 2024 10:43:00 +0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>주식</td>\n",
       "      <td>토스증권, ‘주식모으기’ 서비스 수수료 무료화 선언</td>\n",
       "      <td>https://view.asiae.co.kr/article/2024081209554...</td>\n",
       "      <td>Mon, 12 Aug 2024 09:55:00 +0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>주식</td>\n",
       "      <td>토스증권 \"주식모으기 이제 무료로 이용하세요\"</td>\n",
       "      <td>https://www.dt.co.kr/contents.html?article_no=...</td>\n",
       "      <td>Mon, 12 Aug 2024 09:26:00 +0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>주식</td>\n",
       "      <td>토스證, '주식모으기' 서비스 거래 수수료 안 받는다</td>\n",
       "      <td>https://biz.sbs.co.kr/article_hub/20000186523?...</td>\n",
       "      <td>Mon, 12 Aug 2024 09:54:00 +0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>금융</td>\n",
       "      <td>농협상호금융, ‘쌀맛 나는 하루’ 캠페인 전개</td>\n",
       "      <td>https://www.asiatoday.co.kr/view.php?key=20240...</td>\n",
       "      <td>Mon, 12 Aug 2024 17:44:00 +0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>금융</td>\n",
       "      <td>대규모 부정대출 우리금융, 이제 와 '무관용 원칙' 공표</td>\n",
       "      <td>https://www.kbanker.co.kr/news/articleView.htm...</td>\n",
       "      <td>Mon, 12 Aug 2024 14:12:00 +0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>금융</td>\n",
       "      <td>하나금융, 어르신 보양식 나눔 봉사활동 실시</td>\n",
       "      <td>http://www.babytimes.co.kr/news/articleView.ht...</td>\n",
       "      <td>Mon, 12 Aug 2024 09:34:00 +0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>금융</td>\n",
       "      <td>하나금융, 혹서기 취약한 어르신들 위한 봉사활동 진행</td>\n",
       "      <td>http://www.thefirstmedia.net/news/articleView....</td>\n",
       "      <td>Mon, 12 Aug 2024 15:44:00 +0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>금융</td>\n",
       "      <td>금감원, 이대와 국제금융컨퍼런스·채용설명회 개최</td>\n",
       "      <td>http://www.edaily.co.kr/news/newspath.asp?news...</td>\n",
       "      <td>Mon, 12 Aug 2024 08:45:00 +0900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category                                Title  \\\n",
       "0         주식       '부동산보단 주식'…투자 전환 강조한 김병환 금융위원장   \n",
       "1         주식  국민연금 \"핀란드 주식투자 배당 세금 96억원 환급 소송 승소\"   \n",
       "2         주식         토스증권, ‘주식모으기’ 서비스 수수료 무료화 선언   \n",
       "3         주식            토스증권 \"주식모으기 이제 무료로 이용하세요\"   \n",
       "4         주식        토스證, '주식모으기' 서비스 거래 수수료 안 받는다   \n",
       "..       ...                                  ...   \n",
       "895       금융            농협상호금융, ‘쌀맛 나는 하루’ 캠페인 전개   \n",
       "896       금융      대규모 부정대출 우리금융, 이제 와 '무관용 원칙' 공표   \n",
       "897       금융             하나금융, 어르신 보양식 나눔 봉사활동 실시   \n",
       "898       금융        하나금융, 혹서기 취약한 어르신들 위한 봉사활동 진행   \n",
       "899       금융           금감원, 이대와 국제금융컨퍼런스·채용설명회 개최   \n",
       "\n",
       "                                         Original Link  \\\n",
       "0       https://www.hankyung.com/article/2024081288721   \n",
       "1    https://www.yna.co.kr/view/AKR2024081205530053...   \n",
       "2    https://view.asiae.co.kr/article/2024081209554...   \n",
       "3    https://www.dt.co.kr/contents.html?article_no=...   \n",
       "4    https://biz.sbs.co.kr/article_hub/20000186523?...   \n",
       "..                                                 ...   \n",
       "895  https://www.asiatoday.co.kr/view.php?key=20240...   \n",
       "896  https://www.kbanker.co.kr/news/articleView.htm...   \n",
       "897  http://www.babytimes.co.kr/news/articleView.ht...   \n",
       "898  http://www.thefirstmedia.net/news/articleView....   \n",
       "899  http://www.edaily.co.kr/news/newspath.asp?news...   \n",
       "\n",
       "                    Publication Date  \n",
       "0    Mon, 12 Aug 2024 17:51:00 +0900  \n",
       "1    Mon, 12 Aug 2024 10:43:00 +0900  \n",
       "2    Mon, 12 Aug 2024 09:55:00 +0900  \n",
       "3    Mon, 12 Aug 2024 09:26:00 +0900  \n",
       "4    Mon, 12 Aug 2024 09:54:00 +0900  \n",
       "..                               ...  \n",
       "895  Mon, 12 Aug 2024 17:44:00 +0900  \n",
       "896  Mon, 12 Aug 2024 14:12:00 +0900  \n",
       "897  Mon, 12 Aug 2024 09:34:00 +0900  \n",
       "898  Mon, 12 Aug 2024 15:44:00 +0900  \n",
       "899  Mon, 12 Aug 2024 08:45:00 +0900  \n",
       "\n",
       "[900 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import html\n",
    "\n",
    "# 네이버 API의 클라이언트 ID와 시크릿 키 설정\n",
    "CLIENT_ID = MY_CLIENT_ID  # 실제 클라이언트 ID를 입력하세요\n",
    "CLIENT_SECRET = MY_CLIENT_SECRET  # 실제 클라이언트 시크릿을 입력하세요\n",
    "\n",
    "# 검색할 키워드 목록\n",
    "SEARCH_QUERIES = [\"주식\", \"채권\", \"금융\"]\n",
    "\n",
    "# API 호출 시 설정\n",
    "DISPLAY_COUNT = 100  # 한 페이지에 표시할 뉴스 항목 수\n",
    "START_INDEX = 1  # 검색 결과의 시작 인덱스\n",
    "END_INDEX = 300  # 검색 결과의 종료 인덱스\n",
    "SORT_ORDER = \"sim\"  # 정렬 방식: \"sim\" (유사도) 또는 \"date\" (날짜)\n",
    "\n",
    "# 뉴스 데이터를 저장할 데이터프레임 초기화\n",
    "news_df = pd.DataFrame(columns=[\"Category\", \"Title\", \"Original Link\", \"Publication Date\"])\n",
    "\n",
    "def fetch_news(query):\n",
    "    \"\"\"\n",
    "    주어진 검색어에 대해 뉴스 데이터를 가져와서 데이터프레임에 추가합니다.\n",
    "    \n",
    "    :param query: 검색어\n",
    "    \"\"\"\n",
    "    global news_df\n",
    "    encoded_query = urllib.parse.quote(query)  # 검색어를 URL 인코딩\n",
    "    current_index = len(news_df)  # 현재 데이터프레임의 인덱스\n",
    "    \n",
    "    for start_index in range(START_INDEX, END_INDEX, DISPLAY_COUNT):\n",
    "        url = f\"https://openapi.naver.com/v1/search/news?query={encoded_query}&display={DISPLAY_COUNT}&start={start_index}&sort={SORT_ORDER}\"\n",
    "        \n",
    "        try:\n",
    "            request = urllib.request.Request(url)\n",
    "            request.add_header(\"X-Naver-Client-Id\", CLIENT_ID)\n",
    "            request.add_header(\"X-Naver-Client-Secret\", CLIENT_SECRET)\n",
    "            response = urllib.request.urlopen(request)\n",
    "            response_code = response.getcode()\n",
    "            \n",
    "            if response_code == 200:\n",
    "                response_body = response.read()\n",
    "                response_dict = json.loads(response_body.decode('utf-8'))\n",
    "                items = response_dict['items']\n",
    "                \n",
    "                for item in items:\n",
    "                    # HTML 태그 제거\n",
    "                    clean_title = re.sub(re.compile('<.*?>'), '', item['title'])\n",
    "                    clean_pub_date = re.sub(re.compile('<.*?>'), '', item['pubDate'])\n",
    "                    \n",
    "                    # 데이터프레임에 뉴스 항목 추가\n",
    "                    news_df.loc[current_index] = [\n",
    "                        query,  # 카테고리 추가\n",
    "                        html.unescape(clean_title),  # HTML 엔티티 제거\n",
    "                        html.unescape(item['originallink']),  # HTML 엔티티 제거\n",
    "                        clean_pub_date\n",
    "                    ]\n",
    "                    current_index += 1\n",
    "            else:\n",
    "                print(f\"Error Code: {response_code}\")\n",
    "                error_details = response.read().decode('utf-8')\n",
    "                print(f\"Error Details: {error_details}\")\n",
    "\n",
    "        except urllib.error.HTTPError as e:\n",
    "            print(f\"HTTPError: {e.code} - {e.reason}\")\n",
    "            error_details = e.read().decode('utf-8')\n",
    "            print(f\"Error Details: {error_details}\")\n",
    "\n",
    "# 각 검색어에 대해 뉴스 데이터 가져오기\n",
    "for query in SEARCH_QUERIES:\n",
    "    fetch_news(query)\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "news_df.to_csv('news_data.csv', index=False)\n",
    "print(\"CSV 파일이 'news_data.csv'로 저장되었습니다.\")\n",
    "\n",
    "# 데이터프레임 확인\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카테고리별 뉴스 데이터 개수:\n",
      "Category\n",
      "금융    300\n",
      "주식    300\n",
      "채권    300\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 카테고리별 데이터 개수 확인\n",
    "category_counts = news_df.groupby(\"Category\").size()\n",
    "print(\"카테고리별 뉴스 데이터 개수:\")\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'부동산보단 주식'…투자 전환 강조한 김병환 금융위원장\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['Title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 링크에 접근해서 원문 스크래핑 (실패)\n",
    "p 태그인건 다 갖고오려고 했는데, 뭔가 뉴스 링크 들어가면 뉴스가 아니라 다른게 뜨는 듯..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 뉴스 내용 추출 함수\n",
    "def extract_news_content(url):\n",
    "    \"\"\"\n",
    "    주어진 URL에서 뉴스 내용을 추출합니다.\n",
    "    :param url: 뉴스 URL\n",
    "    :return: 추출된 뉴스 내용\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    content = ' '.join([p.text for p in paragraphs])\n",
    "    return content[:1000]  # 첫 1000자만 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.hankyung.com/article/2024081288721'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일에서 데이터프레임으로 읽어오기\n",
    "news_df = pd.read_csv('news_data.csv')\n",
    "\n",
    "# 데이터프레임 확인\n",
    "news_df['Original Link'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'한국경제 회원이 되어 보세요 지금 바로 한국경제 회원으로 가입하시고, 독점 혜택을 누려보세요 \\n                        이미 회원이시면 로그인을 클릭해 주세요\\n                      계정관리 마이뉴스 기자 구독 관리 마이증권 내 포트폴리오 관리 ⓒ 한경닷컴, 무단전재 및 재배포 금지 \\n\\n                                                                요양원 규제는 그대로…반쪽짜리 완화 비판도\\n                                                            \\n \\n                                                            앞으로 보험회사가 방문 요양 서비스 시장에 직접 진출할 수 있게 된다. 지금까지는 자회사를 통해 제한적으로만 허용됐다. 다만 요양원 등 요양시설 사업은 여전히 진입 규제에 막혀 있어 일각에서는 ‘반쪽짜리&...\\n                                                         \\n\\n                                                                \"여행상품 구매자도 책임 있다\"…커지는 티메프 환불 갈등\\n                                                            \\n \\n                                                            티몬·위메프(티메프)의 여행상품과 상품권 환불 책임을 둘러싼 갈등이 커지고 있다. 환불금을 놓고 카드사와 전자지급결제대행(PG)사, 여행사 간 갈등이 불거진 가운데 소비자도 계약 상대방으로서 일정 부분 ...\\n                                                         \\n\\n                                     '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 뉴스 추출해보기\n",
    "extract_news_content(news_df['Original Link'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain WebBaseLoader 활용\n",
    "한줄기의 희망!!! 전체 문서를 다 가져와줌 <br>\n",
    "이걸 이용해서 개행문자 기준으로 나눴을 때, 글자 길이가 길면 본문으로 간주 <br>\n",
    "글자 길이 : 300자 <br>\n",
    "(100자는 옆에 뜨는 광고도 다 가져오고, 너무 크면 가끔 문단을 나눈다고 p태그 여러개 적용해서 뉴스 기사 쓴 것들이 있어서 원문 소실됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'news_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebBaseLoader\n\u001b[0;32m----> 3\u001b[0m loader \u001b[38;5;241m=\u001b[39m WebBaseLoader(\u001b[43mnews_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Link\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m docs \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m      6\u001b[0m docs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'news_df' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(news_df['Original Link'][0])\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                김병환 금융위원장(사진)은 12일 “밸류업(기업 가치 제고) 정책이 안착하면 경제 구조가 부채 중심에서 자본 중심으로 전환될 것”이라고 말했다.그는 이날 LG, 현대자동차, 포스코와 유관기관이 참여한 가운데 연 기업 밸류업 상장기업 간담회에서 “밸류업 정책이 우리 경제의 역동성·안정성을 높이고 지속가능한 성장에 기여할 것”이라며 이같이 설명했다.김 위원장의 발언은 자산 대부분에 대출금까지 얹어 부동산에 투자하는 가계 자산 운용 구조를 바꿔야 한다는 의미로 해석된다. 부동산보다는 주식 등에 투자해 노후 자산을 불려야 한다는 것이다.김 위원장은 “정부는 다음달 코리아 밸류업 지수를 발표하고 올 4분기 이 지수를 기초자산으로 하는 상장지수펀드(ETF)를 출시하는 작업을 차질 없이 추진할 것”이라고 말했다. 최근 증시가 급등락한 것과 관련해서는 “우리 증시의 과도한 낙폭과 더딘 회복 속도에 대해 아쉬워하는 평가가 있다”며 “보다 단단하고 회복력을 갖춘 증시로 도약하려면 밸류업 확산·내실화가 필요하다”고 했다.김익환 기자 lovepen@hankyung.com'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_long_texts(text, min_length=300):\n",
    "    \"\"\"\n",
    "    주어진 텍스트에서 개행 문자로 분할한 후, 길이가 min_length 이상인 모든 텍스트 조각을 본문으로 추출\n",
    "    :param text: 전체 뉴스 기사 텍스트\n",
    "    :param min_length: 본문으로 간주할 최소 문자 수\n",
    "    :return: 본문으로 간주된 텍스트 조각들\n",
    "    \"\"\"\n",
    "    # 개행 문자(\\n)를 기준으로 텍스트를 분할\n",
    "    segments = text.split('\\n')\n",
    "    \n",
    "    # 길이가 min_length 이상인 텍스트 조각을 찾음\n",
    "    long_texts = [segment for segment in segments if len(segment) > min_length]\n",
    "    \n",
    "    # 모든 긴 텍스트 조각을 하나의 문자열로 결합\n",
    "    return '\\n'.join(long_texts)\n",
    "\n",
    "text = docs[0].page_content\n",
    "\n",
    "content_text = extract_long_texts(text)\n",
    "content_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naver news api와 WebBaseLoader를 활용한 뉴스 원문 스크래핑 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_CLIENT_ID = \"hZm0ny7bv69wAHcdYffq\"\n",
    "MY_CLIENT_SECRET = \"pIyAPPtzD2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching content for article: [단독] 도이치 주식 최다 수익자, 윤 대통령 고액 후원했다\n",
      "Fetching content for article: [경제PICK] 주식 시세처럼...실시간 '부동산 통계 시스템'\n",
      "Fetching content for article: 애물단지 전락한 물납주식…상속인 되살 때 최대 50% 할인해준다\n",
      "Fetching content for article: 30대그룹 공익법인, 계열사 보유주식 늘리고 기부액 줄였다\n",
      "Fetching content for article: 정부, 안 팔리는 '물납주식', 상속인 다시 사도록 규제 푼다\n",
      "Fetching content for article: 수그러들지 않는 美경기침체 우려…골드만 \"가능성 29%→41%로\"\n",
      "Fetching content for article: 정부, 물납주식 우선매수제도 완화…매각주체, 캠코→증권사로\n",
      "Fetching content for article: 국유지 19곳에 청년주택 공급…투자형 물납주식 매각 증권사가 주관\n",
      "Fetching content for article: “외국인 지난달 국내 주식 2.4조 순매수”..9개월 연속\n",
      "Fetching content for article: 지난달 외국인 국내주식 2조5천억원 순매수\n",
      "Fetching content for article: 주식 양도세 자칫 '세금폭탄' 맞는다…국세청이 알려주는 신고 꿀팁\n",
      "Fetching content for article: 지난달 외국인 국내주식 2.5조 순매수…9개월째 '사자'\n",
      "Fetching content for article: \"금투세, 주식만큼 채권시장에도 부정적\"\n",
      "Fetching content for article: 정부, 노후청사 개발해 청년주택 2.2만가구 공급… 상속인 물납주식 재매입 요...\n",
      "Fetching content for article: 국고 속 '노는 재산' 굴린다...국유지 위 청년주택 짓고 '물납주식' 처분↑\n",
      "Fetching content for article: 최상목 \"국고수입↑ 가업상속기업 지원…물납주식 '우선매수제' 개선\"\n",
      "Fetching content for article: 30대그룹 공익재단, 계열사 주식 늘었지만…계열사 기부금 줄었다\n",
      "Fetching content for article: '부동산보단 주식'…투자 전환 강조한 김병환 금융위원장\n",
      "Fetching content for article: 주식 투자 멘탈, 마지막 퍼즐은 '상상력' [이환주의 개미지옥]\n",
      "Fetching content for article: 30대그룹 공익재단, 계열사 주식 늘었지만…계열사 기부금 줄어\n",
      "Fetching content for article: 일학개미 희비…주식ETF '울상' 엔화ETF는 '환호'\n",
      "Fetching content for article: “주주 맘고생 6주 끝났단 신호” 엔비디아 ‘불기둥’…韓 짝꿍 ‘이 주식’...\n",
      "Fetching content for article: 에코프로도 별 수 없네…주식분할·무상증자에도 주가는 주르륵\n",
      "Fetching content for article: 美 주식 주간거래 하루 더 연기…보상은 물건너갈 듯\n",
      "Fetching content for article: 외국인, 9개월 연속 국내주식 순매수했다\n",
      "Fetching content for article: 외인, 지난달 국내 주식 2조4960억 순매수…9개월째 '바이 코리아'\n",
      "Fetching content for article: 아이패밀리에스씨 김태욱 회장, 자사주식 장내 추가 매입\n",
      "Fetching content for article: 지난달 외국인 국내 주식 2조5000억원 사들여...9개월 연속 매수세\n",
      "Fetching content for article: 토스증권, 해외주식 호조에 흑자전환\n",
      "Fetching content for article: iM증권(舊하이투자증권), 사명 변경 기념...대표주식 지급\n",
      "Fetching content for article: 외국인, 지난달 국내주식 2.5조 순매수…9개월째 '사자'\n",
      "Fetching content for article: 내달 2일까지 주식양도세 예정신고…국세청 '실수 사례집' 연재\n",
      "Fetching content for article: \"한 번도 판 적 없다\" 월세 살며 주식 올인 직장인…9년만에 이룬 수익은\n",
      "Fetching content for article: 국민연금 \"핀란드 주식투자 배당 세금 96억원 환급 소송 승소\"\n",
      "Fetching content for article: 오늘의 주식시장 개장 시황\n",
      "Fetching content for article: 토스증권, ‘주식모으기’ 서비스 수수료 무료화 선언\n",
      "Fetching content for article: 애물단지 된 물납주식, 상속인이 다시 사도록…'감액규정' 신설\n",
      "Fetching content for article: 30대 그룹 공익재단, 계열사 주식은 늘었지만 기부금은 줄었다\n",
      "Fetching content for article: 외국인 지난달 국내 주식 2조4000억 순매수…9개월 연속\n",
      "Fetching content for article: 지난달 외국인 국내주식 2조5천억원 순매수…9개월 연속 '사자'\n",
      "Fetching content for article: “미안하지만 이 주식 샀어요”…일촉즉발 중동위기에 사상 최고가 껑충\n",
      "Fetching content for article: 토스증권 \"주식모으기 이제 무료로 이용하세요\"\n",
      "Fetching content for article: 토스證, '주식모으기' 서비스 거래 수수료 안 받는다\n",
      "Fetching content for article: iM증권, 사명 변경 기념 대고객 이벤트\n",
      "Fetching content for article: 외국인, 주식시장서 7개월 연속 '바이 코리아'…채권은 순회수\n",
      "Fetching content for article: 외국인, 지난달 국내 주식 2.5조원 순매수…9개월 연속 ‘사자’\n",
      "Fetching content for article: 2035년까지 국유재산 활용 청년주택 2.2만호 공급…물납주식 매각 활성화\n",
      "Fetching content for article: 국세청, '주식 양도소득세 자주 실수하는 사례' 제작·게재\n",
      "Fetching content for article: '주식 양도세' 어떻게 신고하지? 꼭 하는 '실수'들 모았다\n",
      "Fetching content for article: 주식 양도소득세 신고는…국세청, 실수 사례 공개\n",
      "Fetching content for article: ﻿토스증권, 상반기 영업이익 306억원…연간 목표 조기 달성\n",
      "Fetching content for article: '대주주 기준은 계약일? 결제일?'…주식 양도세 실수사례\n",
      "Fetching content for article: 지난달 외국인 국내 주식에 2.4조 투자… 9개월 연속 순매수\n",
      "Fetching content for article: 국민연금 \"핀란드 주식투자 배당 세금 96억원 환급 소송 승소\"\n",
      "Fetching content for article: 증권가, 방학 맞아 어린이 대상 금융·주식 체험 활발\n",
      "Fetching content for article: 세금 대신 낸 물납주식, 재매입요건 완화한다…증권사도 매각대행\n",
      "Fetching content for article: '1조 매출' 안선영도 억대 주식 사기…\"방송 출연 유명 애널 믿었는데\" 고백\n",
      "Fetching content for article: 알쏭달쏭 '주식 양도소득세 신고'…\"오답 알려드려요\"\n",
      "Fetching content for article: 증권사 \"미국 주식 거래 먹통, 피해자 보상 안 돼\"\n",
      "Fetching content for article: 해외주식 거래액 2배 증가…토스증권, 반년 만에 연간 목표 영업익 달성\n",
      "Fetching content for article: \"주식 양도세 신고 이제 실수하지 마세요\"\n",
      "Fetching content for article: \"새로운 위기가 온다…15일은 첫 시험대\" [정경준의 주식어때]\n",
      "Fetching content for article: 7월 외국인 국내주식 2.5조 순매수…9개월째 ‘사자’\n",
      "Fetching content for article: 장외주식은 대주주 여부와 관계없이 양도세 신고·납부해야\n",
      "Fetching content for article: 대기업 공익재단 중 계열사 주식 비중 최다 1위 삼라희망, 2위 삼성복지재단\n",
      "Fetching content for article: 토스증권, ‘주식모으기’ 서비스 수수료 무료화\n",
      "Fetching content for article: 물납주식 매각 활성화…우선매수제도 완화·투자형매각 개선\n",
      "Fetching content for article: 30대그룹 공익재단, 계열사 주식은 늘고 기부금은 줄었다\n",
      "Fetching content for article: 국세청 \"주식 양도소득세 신고 실수하지 마세요\"\n",
      "Fetching content for article: 상속인 물납주식 재매입 할 수 있게 우선매수제도 완화\n",
      "Fetching content for article: 외국인, 지난달 국내주식 2조5000억원 순매수…9개월 연속 '사자'\n",
      "Fetching content for article: 30대그룹 공익재단, 계열사 주식 늘었지만 계열사 기부금은 줄어\n",
      "Fetching content for article: 지난달 외국인 국내주식 2.5조 순매수…9개월 연속 ‘사자’\n",
      "Fetching content for article: 토스증권, ‘주식모으기’ 서비스 수수료 무료화 선언\n",
      "Fetching content for article: 美 증시 후퇴에… 서학 개미, 주식은 팔고 ETF 샀다\n",
      "Fetching content for article: 주식시장 마감시황\n",
      "Fetching content for article: '1조 CEO' 안선영, 억대 주식 사기 당했다 \"10년 모은 돈인데..\"(영업비밀)[종...\n",
      "Fetching content for article: 최상목 \"노후 청·관사 개발해 청년주택 2만2000호 공급할 것\"\n",
      "Fetching content for article: [뉴욕마켓워치] PPI로 물가 승리 또다시 확인…주식·채권↑달러 급락\n",
      "Fetching content for article: 7월 외국인 국내 주식 2.5조 순매수…9개월 연속 바이코리아\n",
      "Fetching content for article: 7월 外人 국내주식 2조4960억원 순매수\n",
      "Fetching content for article: 토스증권, 오늘부터 '주식모으기' 서비스 수수료 무료\n",
      "Fetching content for article: 토스증권, '주식 모으기' 서비스 수수료 무료화\n",
      "Fetching content for article: ‘빚 갚고, 가상화폐·주식 투자’… 공금 6억원 빼돌린 청주시 6급 공무원\n",
      "Fetching content for article: 30대그룹 공익재단, 계열사 주식↑ 기부금↓\n",
      "Fetching content for article: 정부, 물납주식 매각 활성화 방안 등 논의\n",
      "Fetching content for article: 오늘의 주식시장 마감 시황\n",
      "Fetching content for article: \"폭락장=주식 바겐세일\"…'강심장' 개미들, 5조 쓸어담았다\n",
      "Fetching content for article: 日 주식 '100주 구매' 규정 풀리나…개인투자 활성화 논의\n",
      "Fetching content for article: \"경기침체 버틸 미국 주식\"…헤지펀드 거물의 조언\n",
      "Fetching content for article: 外人 지난달 국내주식 2.5兆 순매수…9개월 연속 '사자' [투자360]\n",
      "Fetching content for article: 주식 양도세 예정신고때 '손익통산' 유의사항\n",
      "Fetching content for article: 토스증권, '주식모으기' 서비스 거래 수수료 무료\n",
      "Fetching content for article: 오늘의 주식시장 마감 시황은?\n",
      "Fetching content for article: '1조 CEO' 안선영, 억대 주식 사기 당해 \"뉴스에도 나와\" (영업비밀)[종합]\n",
      "Fetching content for article: BoA \"엔비디아 반등할 1순위 주식\"…주가 4% 급등(상보)\n",
      "Fetching content for article: 7월 외국인 국내주식 2.5조 순매수···9개월 연속 '사자'\n",
      "Fetching content for article: ‘1조 신화 CEO’ 안선영도 억대 주식 사기 당했다···“방송 출연 유명 애...\n",
      "Fetching content for article: ‘툭하면 급등락’ K주식에 나스닥도 데였네”…공모가 대비 반토막 난 네이버...\n",
      "Fetching content for article: 반도체 반등 월가 픽…가장 선호주식 3개는 ‘이것’\n",
      "Fetching content for article: \"주식 양도세율 잘못 신고하면 가산세 물어요\"\n",
      "Fetching content for article: 외국인, 7월 주식 순매수세 주춤…채권은 2개월 연속 순회수\n",
      "Fetching content for article: \"서학개미 생큐\"…증권업계 역대급 실적 이끈 해외 주식투자\n",
      "Fetching content for article: 국세청, '주식 양도세' 관련 자주 실수하는 사례 모음집 제작\n",
      "Fetching content for article: 30대그룹 공익재단, 계열사 주식 늘고 기부금은 줄어\n",
      "Fetching content for article: 계열사 주식 늘었지만 기부액 줄었다\n",
      "Fetching content for article: 토스증권, 오늘부터 '주식모으기' 거래수수료 0원\n",
      "Fetching content for article: 국민연금, 핀란드 상장주식 배당원천세 환급 소송 '승소'…96억원 환급\n",
      "Fetching content for article: 토스증권, 주식모으기 서비스 수수료 무료화 선언\n",
      "Fetching content for article: 상속세로 낸 물납주식 매각 증권사에 맡긴다…내달 입찰 공고\n",
      "Fetching content for article: 美 7월 도매물가 전월比 0.1% 상승 '예상 밑돌아'...국채수익률↓·주식 ↑\n",
      "Fetching content for article: 외국인 9개월 연속 '사자'…국내주식 2.5조 순매수\n",
      "Fetching content for article: IPO 훈풍에 비상장 주식 투자로…‘포모’ 개미 몰렸다\n",
      "Fetching content for article: 토스증권, ‘주식모으기’ 서비스 수수료 무료화 선언\n",
      "Fetching content for article: 지난달 외국인 국내주식 2조 5천억 원 순매수\n",
      "Fetching content for article: ﻿토스증권, '주식모으기' 서비스 수수료 전면 무료화\n",
      "Fetching content for article: 안선영 \"홈쇼핑 매출 1조원 진작 넘어…주식·코인 안 해\"\n",
      "Fetching content for article: 外人, 9개월 연속 '사자'…7월 국내주식 2조4960억 순매수\n",
      "Fetching content for article: 日 '주식 최소 100주 구매' 규정 완화되나…개인투자 겨냥 논의\n",
      "Fetching content for article: [주식 초고수는 지금] 미국 FDA 승인 기대감…유한양행, 순매수 1위\n",
      "Fetching content for article: “주식모으기, 이제 무료로 이용”… 토스證, 거래 수수료 없앴다\n",
      "Fetching content for article: 7월 외국인 국내주식 2조4960억원 순매수…9개월 연속 '사자'\n",
      "Fetching content for article: 오늘의 주식시장 개장 시황\n",
      "Fetching content for article: 외국인투자자 7월 국내주식 2조5천억 순매수, 9개월 연속 '사자' 행진\n",
      "Fetching content for article: 외국인투자자, 9개월 연속 주식 순매수\n",
      "Fetching content for article: 토스증권, 오늘부터 ‘주식모으기’ 거래수수료 0원\n",
      "Fetching content for article: 작년 말일 주식 판 대주주…양도세 신고 안할 땐 가산세 문다\n",
      "Fetching content for article: 외국인 투자자, 지난달 국내주식 2.5조원 '순매수'\n",
      "Fetching content for article: 외국인 7월 국내 주식 2조5000억 순매수…30.1% 보유\n",
      "Fetching content for article: '부동산'·'주식'에 과감한 베팅...'머니 무브' 가속\n",
      "Fetching content for article: ‘1조 매출 CEO’ 안선영도 억대 주식 사기 “방송 출연 경력 믿었는데”(영업...\n"
     ]
    },
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='www.newsen.com', port=443): Max retries exceeded with url: /news_view.php?uid=202408130752322410 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1095\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/urllib3/connection.py:652\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m server_hostname_rm_dot \u001b[38;5;241m=\u001b[39m server_hostname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 652\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/urllib3/connection.py:805\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[0;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[1;32m    803\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[0;32m--> 805\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/urllib3/util/ssl_.py:465\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/urllib3/util/ssl_.py:509\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[0;32m--> 509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/ssl.py:1375\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1375\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py:490\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    489\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[0;31mSSLError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.newsen.com', port=443): Max retries exceeded with url: /news_view.php?uid=202408130752322410 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 118\u001b[0m\n\u001b[1;32m    115\u001b[0m     fetch_news(query)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# 뉴스 링크에서 원문을 가져와 데이터프레임 업데이트\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[43mupdate_news_with_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# 데이터프레임을 CSV 파일로 저장\u001b[39;00m\n\u001b[1;32m    121\u001b[0m news_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[5], line 106\u001b[0m, in \u001b[0;36mupdate_news_with_content\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mor\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching content for article: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_article_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginal Link\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content:\n\u001b[1;32m    108\u001b[0m         content_text \u001b[38;5;241m=\u001b[39m extract_long_texts(content)\n",
      "Cell \u001b[0;32mIn[5], line 81\u001b[0m, in \u001b[0;36mfetch_article_content\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m주어진 뉴스 기사 URL에서 본문을 가져옵니다.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m:param url: 뉴스 기사 URL\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m:return: 뉴스 기사 본문\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m loader \u001b[38;5;241m=\u001b[39m WebBaseLoader(url)\n\u001b[0;32m---> 81\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m docs:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/langchain_core/document_loaders/base.py:30\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/langchain_community/document_loaders/web_base.py:261\u001b[0m, in \u001b[0;36mWebBaseLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Lazy load text from the url(s) in web_path.\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweb_paths:\n\u001b[0;32m--> 261\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbs_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     text \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mget_text(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbs_get_text_kwargs)\n\u001b[1;32m    263\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m _build_metadata(soup, path)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/langchain_community/document_loaders/web_base.py:240\u001b[0m, in \u001b[0;36mWebBaseLoader._scrape\u001b[0;34m(self, url, parser, bs_kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_parser\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_parser(parser)\n\u001b[0;32m--> 240\u001b[0m html_doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequests_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraise_for_status:\n\u001b[1;32m    242\u001b[0m     html_doc\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow_env/lib/python3.10/site-packages/requests/adapters.py:698\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mSSLError\u001b[0m: HTTPSConnectionPool(host='www.newsen.com', port=443): Max retries exceeded with url: /news_view.php?uid=202408130752322410 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import html\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 네이버 API의 클라이언트 ID와 시크릿 키 설정\n",
    "CLIENT_ID = MY_CLIENT_ID  # 실제 클라이언트 ID를 입력하세요\n",
    "CLIENT_SECRET = MY_CLIENT_SECRET  # 실제 클라이언트 시크릿을 입력하세요\n",
    "\n",
    "# 검색할 키워드 목록\n",
    "SEARCH_QUERIES = [\"주식\", \"채권\", \"금융\"]\n",
    "\n",
    "# API 호출 시 설정\n",
    "DISPLAY_COUNT = 100  # 한 페이지에 표시할 뉴스 항목 수\n",
    "START_INDEX = 1  # 검색 결과의 시작 인덱스\n",
    "END_INDEX = 300  # 검색 결과의 종료 인덱스\n",
    "SORT_ORDER = \"sim\"  # 정렬 방식: \"sim\" (유사도) 또는 \"date\" (날짜)\n",
    "\n",
    "# 뉴스 데이터를 저장할 데이터프레임 초기화\n",
    "news_df = pd.DataFrame(columns=[\"Category\", \"Title\", \"Original Link\", \"Publication Date\", \"Content\"])\n",
    "\n",
    "def fetch_news(query):\n",
    "    \"\"\"\n",
    "    주어진 검색어에 대해 뉴스 데이터를 가져와서 데이터프레임에 추가합니다.\n",
    "    \n",
    "    :param query: 검색어\n",
    "    \"\"\"\n",
    "    global news_df\n",
    "    encoded_query = urllib.parse.quote(query)  # 검색어를 URL 인코딩\n",
    "    current_index = len(news_df)  # 현재 데이터프레임의 인덱스\n",
    "    \n",
    "    for start_index in range(START_INDEX, END_INDEX, DISPLAY_COUNT):\n",
    "        url = f\"https://openapi.naver.com/v1/search/news?query={encoded_query}&display={DISPLAY_COUNT}&start={start_index}&sort={SORT_ORDER}\"\n",
    "        \n",
    "        try:\n",
    "            request = urllib.request.Request(url)\n",
    "            request.add_header(\"X-Naver-Client-Id\", CLIENT_ID)\n",
    "            request.add_header(\"X-Naver-Client-Secret\", CLIENT_SECRET)\n",
    "            response = urllib.request.urlopen(request)\n",
    "            response_code = response.getcode()\n",
    "            \n",
    "            if response_code == 200:\n",
    "                response_body = response.read()\n",
    "                response_dict = json.loads(response_body.decode('utf-8'))\n",
    "                items = response_dict['items']\n",
    "                \n",
    "                for item in items:\n",
    "                    # HTML 태그 제거\n",
    "                    clean_title = re.sub(re.compile('<.*?>'), '', item['title'])\n",
    "                    clean_pub_date = re.sub(re.compile('<.*?>'), '', item['pubDate'])\n",
    "                    \n",
    "                    # 뉴스 항목을 데이터프레임에 추가\n",
    "                    news_df.loc[current_index] = [\n",
    "                        query,  # 카테고리 추가\n",
    "                        html.unescape(clean_title),  # HTML 엔티티 제거\n",
    "                        html.unescape(item['originallink']),  # HTML 엔티티 제거\n",
    "                        clean_pub_date,\n",
    "                        ''  # 본문 내용은 빈 문자열로 초기화\n",
    "                    ]\n",
    "                    current_index += 1\n",
    "            else:\n",
    "                print(f\"Error Code: {response_code}\")\n",
    "                error_details = response.read().decode('utf-8')\n",
    "                print(f\"Error Details: {error_details}\")\n",
    "\n",
    "        except urllib.error.HTTPError as e:\n",
    "            print(f\"HTTPError: {e.code} - {e.reason}\")\n",
    "            error_details = e.read().decode('utf-8')\n",
    "            print(f\"Error Details: {error_details}\")\n",
    "\n",
    "def fetch_article_content(url):\n",
    "    \"\"\"\n",
    "    주어진 뉴스 기사 URL에서 본문을 가져옵니다.\n",
    "    \n",
    "    :param url: 뉴스 기사 URL\n",
    "    :return: 뉴스 기사 본문\n",
    "    \"\"\"\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    if docs:\n",
    "        return docs[0].page_content\n",
    "    return \"\"\n",
    "\n",
    "def extract_long_texts(text, min_length=300):\n",
    "    \"\"\"\n",
    "    주어진 텍스트에서 개행 문자로 분할한 후, 길이가 min_length 이상인 모든 텍스트 조각을 본문으로 추출\n",
    "    \n",
    "    :param text: 전체 뉴스 기사 텍스트\n",
    "    :param min_length: 본문으로 간주할 최소 문자 수\n",
    "    :return: 본문으로 간주된 텍스트 조각들\n",
    "    \"\"\"\n",
    "    segments = text.split('\\n')\n",
    "    long_texts = [segment for segment in segments if len(segment) > min_length]\n",
    "    return '\\n'.join(long_texts)\n",
    "\n",
    "def update_news_with_content():\n",
    "    \"\"\"\n",
    "    데이터프레임에 저장된 뉴스 링크를 통해 원문을 가져와 데이터프레임을 업데이트합니다.\n",
    "    \"\"\"\n",
    "    global news_df\n",
    "    for index, row in news_df.iterrows():\n",
    "        if pd.isna(row['Content']) or row['Content'] == '':\n",
    "            print(f\"Fetching content for article: {row['Title']}\")\n",
    "            content = fetch_article_content(row['Original Link'])\n",
    "            if content:\n",
    "                content_text = extract_long_texts(content)\n",
    "                news_df.at[index, 'Content'] = content_text\n",
    "            else:\n",
    "                print(f\"Failed to fetch content for URL: {row['Original Link']}\")\n",
    "\n",
    "# 각 검색어에 대해 뉴스 데이터 가져오기\n",
    "for query in SEARCH_QUERIES:\n",
    "    fetch_news(query)\n",
    "\n",
    "# 뉴스 링크에서 원문을 가져와 데이터프레임 업데이트\n",
    "update_news_with_content()\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "news_df.to_csv('news_data.csv', index=False)\n",
    "print(\"CSV 파일이 'news_data.csv'로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
